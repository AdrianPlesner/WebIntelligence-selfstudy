{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self study 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this self study we directly continue with what we started in self study 5\n",
    "\n",
    "**Task 2:** For the same user, and the same train/test split, implement the user-based neighborhood method. How does the RMSE compare to what you got in the content-based approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "R=np.genfromtxt('u.data',dtype=int)\n",
    "\n",
    "#Sort users per number of ratings\n",
    "Nratings=np.zeros(943)\n",
    "for i in range(943):\n",
    "    Nratings[i]=len(np.where(R[:,0]==i+1)[0])\n",
    "\n",
    "#Get users with most ratings and make train/test split\n",
    "users = np.where(Nratings>500)\n",
    "ratID = np.where(R[::,0] == users[0][0]+1)\n",
    "ratings = [R[i, 1:3] for i in ratID[0]]\n",
    "\n",
    "split = len(ratings) // 3\n",
    "train = pd.DataFrame(ratings[:2*split], columns=[\"Movie ID\", \"Rating\"])\n",
    "test = pd.DataFrame(ratings[2*split:], columns=[\"Movie ID\", \"Rating\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rating(train, movie, user):\n",
    "    users = np.where(R[::,1] == movie)\n",
    "    avg_rating = np.average(train[\"Rating\"])\n",
    "    train[\"Relative Rating\"] = train[\"Rating\"] - avg_rating\n",
    "    result = []\n",
    "    users = [R[i,0] for i in users[0] if i != user]\n",
    "    for us in users:\n",
    "        ratIDs = np.where(R[::,0] == us)[0]\n",
    "        ratings = np.asarray([R[i,1:3] for i in ratIDs])\n",
    "        \n",
    "        user_avg = np.average(ratings[::,1])\n",
    "        ratings = np.c_[ratings, [row[1] - user_avg for row in ratings]]\n",
    "        common_movies = [int(i) for i in ratings[::,0] if i in train[\"Movie ID\"].values]\n",
    "        common_movies.sort()\n",
    "        old_user_ratings = np.asarray([train.values[[np.where(train[\"Movie ID\"].values == mov)[0]], 2][0] for mov in common_movies])[::,0]\n",
    "        new_user_ratings = np.asarray([ratings[np.where(ratings[::,0] == mov)[0], 2] for mov in common_movies])[::,0]\n",
    "        sim = np.dot(old_user_ratings, new_user_ratings)/ (np.linalg.norm(old_user_ratings) * np.linalg.norm(new_user_ratings))\n",
    "        result.append(ratings[np.where(ratings[::,0] == movie)[0][0],1] * sim)\n",
    "    return np.average(result) + avg_rating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9077643022526676"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_rating(train, test.values[0,0], users[0][0]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9077643022526676\n",
      "3.774691324485744\n",
      "3.8639875760766134\n",
      "3.8649223248949798\n",
      "4.074859743560783\n",
      "4.000175511108554\n",
      "3.682458982968191\n",
      "3.776770273240651\n",
      "3.922232709139133\n",
      "3.802302637873435\n",
      "3.8617964220364343\n",
      "3.8967464041495927\n",
      "3.887686928246365\n",
      "3.9318470051583625\n",
      "3.842330252868388\n",
      "3.803166115001309\n",
      "3.718930235440606\n",
      "3.710302364690555\n",
      "3.852738863402953\n",
      "3.589608335147553\n",
      "3.4465262134247725\n",
      "3.6791194988321188\n",
      "3.698268715365163\n",
      "3.9063685677886286\n",
      "3.966762861977749\n",
      "3.855110975291473\n",
      "3.6560722045378187\n",
      "3.880180877258538\n",
      "3.94947181871142\n",
      "3.805235987709871\n",
      "4.00456192682166\n",
      "3.931977357465313\n",
      "3.634144846206902\n",
      "3.699052521942159\n",
      "3.6898066116506896\n",
      "3.7754597269720036\n",
      "4.005506011946936\n",
      "3.8185288255334835\n",
      "3.766094418514344\n",
      "3.840047739806011\n",
      "3.7205129493638096\n",
      "4.042206567915512\n",
      "3.6999416837116703\n",
      "3.882490576706231\n",
      "3.8088476689971946\n",
      "3.752623039292338\n",
      "3.980116415588862\n",
      "3.9828704952239837\n",
      "3.6751838256777765\n",
      "3.821520428919476\n",
      "3.772261272648136\n",
      "3.490257692493645\n",
      "3.9864931239441592\n",
      "3.9608334393449693\n",
      "3.5342807450514777\n",
      "3.525630981754801\n",
      "3.7294910166772732\n",
      "3.9046269105644735\n",
      "3.8807627599371504\n",
      "3.433062256643994\n",
      "3.665791343896159\n",
      "3.6406810125351785\n",
      "3.7082098505067895\n",
      "3.5193954999324504\n",
      "3.7674721176573507\n",
      "3.4081238168722354\n",
      "3.4774101370880146\n",
      "3.850439448699559\n",
      "3.6514137106163624\n",
      "3.660664828130058\n",
      "3.959240449830903\n",
      "3.599857284319765\n",
      "3.908263800659953\n",
      "3.3777140697321677\n",
      "3.8997375577600986\n",
      "3.7976678843953393\n",
      "3.8882201793298754\n",
      "3.8975596184810506\n",
      "3.9306570064702715\n",
      "3.688278440364063\n",
      "3.774278276786135\n",
      "3.790034445342628\n",
      "3.8709013956729845\n",
      "3.855780301357245\n",
      "3.632012037380106\n",
      "3.7316504622124365\n",
      "3.513838137676053\n",
      "3.75993980264208\n",
      "3.65331576050616\n",
      "3.8033925060658134\n",
      "3.813216274650392\n",
      "3.8894705346045977\n",
      "3.9729854451637854\n",
      "3.8389758806978946\n",
      "3.9772356371078104\n",
      "3.792145849906191\n",
      "3.9378999575812967\n",
      "3.8222299541658242\n",
      "3.756475046002267\n",
      "3.6952876556701475\n",
      "3.8467634076423094\n",
      "3.667739767226863\n",
      "4.018955161856464\n",
      "3.9154669111286062\n",
      "3.7585774965754792\n",
      "3.738826017069331\n",
      "3.7077445624763397\n",
      "3.502973838916573\n",
      "3.6473549433721963\n",
      "3.9330898839955326\n",
      "4.031020702053098\n",
      "4.185194345385829\n",
      "3.6537605584473534\n",
      "3.7049234671797855\n",
      "3.6328532363895354\n",
      "3.5232410081010523\n",
      "3.8572753145792587\n",
      "3.909510174765044\n",
      "3.6376967672118043\n",
      "3.7555727579597518\n",
      "3.4964742986501682\n",
      "3.745790690300752\n",
      "3.8299871366099145\n",
      "4.020588453344144\n",
      "3.8904459583853828\n",
      "3.5961026835380503\n",
      "3.9944155344471843\n",
      "3.81954336520946\n",
      "4.047332898754483\n",
      "3.7658191616647256\n",
      "3.9790060907591727\n",
      "3.987811322238238\n",
      "3.63595903043516\n",
      "3.614813459734042\n",
      "3.8737376386713267\n",
      "3.464498922313922\n",
      "3.760450616756253\n",
      "3.917686508641176\n",
      "3.6756004581000488\n",
      "3.730674240844594\n",
      "3.7887732045675833\n",
      "3.946128214019989\n",
      "3.6467871485050902\n",
      "3.5917446371939383\n",
      "3.909767797309847\n",
      "3.958139057989287\n",
      "3.604883585066057\n",
      "3.7152489485433824\n",
      "3.8454061586805217\n",
      "3.471349962686454\n",
      "4.357558012667219\n",
      "3.561677356356201\n",
      "3.6240247705694246\n",
      "3.760535207984127\n",
      "3.5784192657177543\n",
      "3.941719351447383\n",
      "4.043844404336274\n",
      "3.725011455532953\n",
      "3.989328146982453\n",
      "3.9960493841822875\n",
      "3.7086382711203285\n",
      "3.9513878283673187\n",
      "3.886231179563995\n",
      "4.171524622080714\n",
      "3.9139026860918937\n",
      "3.861068874809654\n",
      "3.9152963494317152\n",
      "3.6345836676666816\n",
      "3.706660180997636\n",
      "3.716124778423076\n",
      "4.165400206099154\n",
      "4.014422741884002\n",
      "3.4977346532022\n",
      "3.8547031583093165\n",
      "3.8719504568278187\n",
      "3.8265789444476543\n",
      "3.609544004424118\n",
      "3.654598421570409\n",
      "3.883884145507541\n",
      "3.5592000654237936\n",
      "4.015132244573641\n",
      "3.5431214965827635\n",
      "3.7222108870740764\n",
      "3.6507694226245913\n",
      "3.7602301264589153\n",
      "3.8835257897979187\n",
      "3.8542901400914142\n",
      "3.795007633735323\n",
      "4.009557383635289\n",
      "3.952400905999481\n",
      "3.500427367842927\n",
      "3.865102456828634\n",
      "4.031063816788824\n",
      "3.573837780959347\n",
      "3.9822301763819805\n",
      "4.386643628459995\n",
      "3.859828578882385\n",
      "3.8805337428735878\n",
      "4.009883558852041\n",
      "3.9789751124063164\n",
      "3.922634122280405\n",
      "3.592662077546416\n",
      "3.6033198161728937\n",
      "3.4458337040913527\n",
      "3.840018608584989\n",
      "3.958129900668307\n",
      "3.4439294448315305\n",
      "4.501453517179021\n",
      "3.789235894833476\n",
      "3.500687364484131\n",
      "3.691532197099\n",
      "3.570747786085337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5238305447405054"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rats = []\n",
    "for m in test.values:\n",
    "    r = estimate_rating(train, m[0], users[0][0]+1)\n",
    "    print(r)\n",
    "    rats.append(r)\n",
    "rats = np.asarray(rats)\n",
    "\n",
    "truth = np.asarray(test['Rating'])\n",
    "RMSE = math.sqrt(np.average((truth-rats) ** 2))\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Now take the whole rating matrix. Divide all the ratings in the matrix into a train and a test set. For the user you have used in Tasks 1 and 2, you should include the same ratings in the test set as before. Be sure that you do the train/test division uniformly at random over all ratings, so that you don't get all the ratings of one movie (or one user) included in the test set (that would lead to some cold start problems).  You can also start with a sub-matrix of the whole rating matrix by selecting only a subset of users, and a subset of movies.\n",
    "\n",
    "Implement the gradient-descent approach for minimizing the error function for the ratings in the training set (you have to pick a value for the number of latent dimensions). Compare the RMSE values you obtain for the test user of tasks 1 and 2 with what you have previously obtained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}