{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self study 9\n",
    "\n",
    "In this self study we are starting to investigate node classification. We are using a standard bibliographic dataset 'Cora', described here: https://relational.fit.cvut.cz/dataset/CORA This is still a rather small network, but a bit more serious than the Lazega lawyers, for example. It is a standard benchmark for node classification techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the Cora data from two files. It turns out to be convenient to read the node attribute data first into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coragraph=nx.readwrite.edgelist.read_edgelist(\"cora.cites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         0     1     2     3     4     5     6     7     8     9     ...  \\\n0       31336     0     0     0     0     0     0     0     0     0  ...   \n1     1061127     0     0     0     0     0     0     0     0     0  ...   \n2     1106406     0     0     0     0     0     0     0     0     0  ...   \n3       13195     0     0     0     0     0     0     0     0     0  ...   \n4       37879     0     0     0     0     0     0     0     0     0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n2703  1128975     0     0     0     0     0     0     0     0     0  ...   \n2704  1128977     0     0     0     0     0     0     0     0     0  ...   \n2705  1128978     0     0     0     0     0     0     0     0     0  ...   \n2706   117328     0     0     0     0     1     0     0     0     0  ...   \n2707    24043     0     0     0     0     0     0     0     0     0  ...   \n\n      1425  1426  1427  1428  1429  1430  1431  1432  1433  \\\n0        0     0     1     0     0     0     0     0     0   \n1        0     1     0     0     0     0     0     0     0   \n2        0     0     0     0     0     0     0     0     0   \n3        0     0     0     0     0     0     0     0     0   \n4        0     0     0     0     0     0     0     0     0   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n2703     0     0     0     0     0     0     0     0     0   \n2704     0     0     0     0     0     0     0     0     0   \n2705     0     0     0     0     0     0     0     0     0   \n2706     0     0     0     0     0     0     0     0     0   \n2707     0     0     0     0     0     0     0     0     0   \n\n                        1434  \n0            Neural_Networks  \n1              Rule_Learning  \n2     Reinforcement_Learning  \n3     Reinforcement_Learning  \n4      Probabilistic_Methods  \n...                      ...  \n2703      Genetic_Algorithms  \n2704      Genetic_Algorithms  \n2705      Genetic_Algorithms  \n2706              Case_Based  \n2707         Neural_Networks  \n\n[2708 rows x 1435 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1425</th>\n      <th>1426</th>\n      <th>1427</th>\n      <th>1428</th>\n      <th>1429</th>\n      <th>1430</th>\n      <th>1431</th>\n      <th>1432</th>\n      <th>1433</th>\n      <th>1434</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31336</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Neural_Networks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1061127</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Rule_Learning</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1106406</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Reinforcement_Learning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13195</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Reinforcement_Learning</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37879</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Probabilistic_Methods</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2703</th>\n      <td>1128975</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>2704</th>\n      <td>1128977</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>2705</th>\n      <td>1128978</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>2706</th>\n      <td>117328</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Case_Based</td>\n    </tr>\n    <tr>\n      <th>2707</th>\n      <td>24043</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Neural_Networks</td>\n    </tr>\n  </tbody>\n</table>\n<p>2708 rows Ã— 1435 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coraatts_pd=pd.read_csv(\"cora.content\",delimiter=\"\\t\",header=None)\n",
    "\n",
    "coraatts_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification problem here always is to predict the subject area of a paper.\n",
    "\n",
    "We also need the data as a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[31336, 0, 0, ..., 0, 0, 'Neural_Networks'],\n       [1061127, 0, 0, ..., 0, 0, 'Rule_Learning'],\n       [1106406, 0, 0, ..., 0, 0, 'Reinforcement_Learning'],\n       ...,\n       [1128978, 0, 0, ..., 0, 0, 'Genetic_Algorithms'],\n       [117328, 0, 0, ..., 0, 0, 'Case_Based'],\n       [24043, 0, 0, ..., 0, 0, 'Neural_Networks']], dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coraatts_arr=np.array(coraatts_pd)\n",
    "\n",
    "coraatts_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem now is that the order of nodes in coraatts does not correspond to the order in which nodes are enumerated by coragraph.nodes. The following fixes this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[35, 0, 0, ..., 0, 0, 'Genetic_Algorithms'],\n       [1033, 0, 0, ..., 0, 0, 'Genetic_Algorithms'],\n       [103482, 0, 0, ..., 0, 0, 'Neural_Networks'],\n       ...,\n       [853155, 0, 0, ..., 0, 0, 'Neural_Networks'],\n       [853115, 0, 0, ..., 0, 0, 'Neural_Networks'],\n       [853118, 0, 0, ..., 0, 0, 'Neural_Networks']], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=[]\n",
    "for n in coragraph.nodes:\n",
    "    rows.append(coraatts_arr[np.where(coraatts_arr[:,0]==int(n))[0],:])\n",
    "coraatts_arr=np.vstack(rows)   \n",
    "\n",
    "coraatts_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Recreate the experiments that are shown in the 'Independent_Classification' notebook. What is more effective, classification based on the attributes contained in coraats_arr, or classification based on coefficients in the singular value decomposition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Extract labels and feature matrixes\n",
    "Y = coraatts_arr[::,1434]\n",
    "features = coraatts_arr[::, 1:1434]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.8457987072945522\n",
      "Confusion matrix: \n",
      "[[32  0  1  3  2  1  5]\n",
      " [ 4 86 12  2  2  1  0]\n",
      " [14  9 92  8  4  1  8]\n",
      " [ 2  1 22 69  1  2  4]\n",
      " [ 1  2  8  3 28  0  4]\n",
      " [ 5  0  4  1  1 21  6]\n",
      " [10  0  9  4  5  6 36]]\n",
      "Accuracy: 0.6715867158671587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix,accuracy_score)\n",
    "# Split data\n",
    "feat_train, feat_test, Y_train, Y_test = train_test_split(features, Y, train_size=0.8)\n",
    "\n",
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier(min_samples_split=32, max_depth=128)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 35   0   1   2   1   2   3]\n",
      " [  1  88   8   3   2   3   2]\n",
      " [ 10   6 102   6   2   2   8]\n",
      " [  4   0  11  76   0   4   6]\n",
      " [  0   3   5   1  36   0   1]\n",
      " [  6   0   1   0   1  27   3]\n",
      " [  5   0   5   4   2   6  48]]\n",
      "Accuracy: 0.7601476014760148\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Use adjacency matrix SVD\n",
    "A=nx.linalg.graphmatrix.adjacency_matrix(coragraph).todense()\n",
    "svdA_features=np.linalg.svd(A)[0][:,:64]\n",
    "svdA_features=np.asarray(svdA_features)\n",
    "\n",
    "feat_train, feat_test, Y_train, Y_test  = train_test_split(svdA_features,Y , train_size=0.8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.948291782086796\n",
      "Confusion matrix: \n",
      "[[ 38   0   9   3   1   4   6]\n",
      " [  2  58  11   0   3   1   4]\n",
      " [  2   7 116  11   1   1  13]\n",
      " [  2   2  19  58   3   0   3]\n",
      " [  4   3   5   0  19   0   6]\n",
      " [  5   2  10   0   0  15   4]\n",
      " [  4   2  18   9   2   5  51]]\n",
      "Accuracy: 0.6549815498154982\n"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier(max_depth=32)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 45   0  11   0   0   5   0]\n",
      " [  0  54  23   0   2   0   0]\n",
      " [  2   2 129   7   2   1   8]\n",
      " [  2   0  24  54   2   0   5]\n",
      " [  4   1  15   1  16   0   0]\n",
      " [  1   0  13   0   0  22   0]\n",
      " [  4   0  23   0   0   6  58]]\n",
      "Accuracy: 0.6974169741697417\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Use lazenga SVD\n",
    "L=nx.linalg.laplacianmatrix.laplacian_matrix(coragraph).todense()\n",
    "svdL_features=np.linalg.svd(L)[0][:,len(L)-128:]\n",
    "svdL_features=np.asarray(svdL_features)\n",
    "\n",
    "feat_train, feat_test, Y_train, Y_test = train_test_split(svdL_features, Y, train_size=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9907663896583564\n",
      "Confusion matrix: \n",
      "[[ 55   0   4   2   0   6   3]\n",
      " [  2  71   4   0   7   0   1]\n",
      " [  3   1 143   4   8   1   6]\n",
      " [  0   0   9  74   0   0   1]\n",
      " [  1   0   2   0  35   0   1]\n",
      " [  3   0   1   0   0  27   1]\n",
      " [  5   0  10   7   1   3  40]]\n",
      "Accuracy: 0.8210332103321033\n"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier(max_depth=32)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 50   1   0   1   1  13   4]\n",
      " [  0  85   0   0   0   0   0]\n",
      " [  0   0 133   3  17   6   7]\n",
      " [  2   0  11  61   3   6   1]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   0  31   1]\n",
      " [  1   1   5   2   4  15  38]]\n",
      "Accuracy: 0.8062730627306273\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Try some other approaches:\n",
    "<ul>\n",
    "    <li> Simple majority vote of the graph neighbors: predict the class label of a <i>test</i> node according to the majority of the class labels among the test node's graph neighbors. Here only neighbors belonging to the <i>training</i> set can be used!  </li>\n",
    "    <li> Think of other node features you can construct, such as node degree, pagerank , etc. (networkx provides functions to compute such things). Does any of this increase your prediction accuracy?</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Majority vote\n",
    "def majority_vote(node):\n",
    "    if node in coragraph.nodes() and node not in feat_train:\n",
    "        result = {}\n",
    "        # Get node neighbours\n",
    "        for e in nx.edges(coragraph, nbunch=(node)):\n",
    "            m = e[1]\n",
    "            if m in feat_train:\n",
    "                idx = feat_train.index(m)\n",
    "                l = Y_train[idx]\n",
    "                if l in result.keys():\n",
    "                    result[l] += 1\n",
    "                else:\n",
    "                    result[l] = 1\n",
    "        # Select most common label of neighbours\n",
    "        r = list(result.keys())\n",
    "        r.sort(key=lambda x: result[x], reverse=True)\n",
    "        if len(r) > 0:\n",
    "            return r[0]\n",
    "        else:\n",
    "            # if node had no neighbours, return most common label\n",
    "            labels = {}\n",
    "            for l in Y_train:\n",
    "                if l in labels.keys():\n",
    "                    labels[l] += 1\n",
    "                else:\n",
    "                    labels[l] = 1\n",
    "            ls = list(labels.keys())\n",
    "            ls.sort(key=lambda x: labels[x], reverse=True)\n",
    "            most_common_label = ls[0]\n",
    "            return most_common_label\n",
    "    else:\n",
    "        return False\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "feat_train, feat_test, Y_train, Y_test = train_test_split([str(x) for x in coraatts_arr[::,0]], Y, train_size=0.8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 34   2   1   0   1   5   5]\n",
      " [  1  59   7   0   1   0   1]\n",
      " [  3   4 133   8   1   1   9]\n",
      " [  1   0   8  74   1   0  11]\n",
      " [  0   3   5   0  34   0   2]\n",
      " [  3   0   1   0   0  29   3]\n",
      " [  0   0  12   4   0   2  73]]\n",
      "Accuracy: 0.8044280442804428\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "Y_pred = [majority_vote(x) for x in feat_test]\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** The sklearn method train_test_split that was used in the Independent Classificaiton notebook to split the data into a training and a test set performs a purely random split. This is not always representative for how labeled and unlabeled nodes are distributed over a network in reality. Create an alternative split by selecting test nodes as follows:\n",
    "<ul>\n",
    "    <li>randomly select a small number of nodes (e.g. 3, 5, 10, ....) as \"seed\" test nodes </li>\n",
    "    <li>add all direct neighbors of nodes in the test set to the test set</li>\n",
    "    <li>... until the test test has reached a size of about 20% of the total number of nodes </li>\n",
    "    </ul>\n",
    "    \n",
    "  Now redo the experiments with this train/test split. Are the results better or worse than what you obtained before with completely random splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "import random\n",
    "total_nodes = len(coragraph.nodes())\n",
    "test_size = total_nodes * 0.05\n",
    "test = []\n",
    "while len(test) < 10:\n",
    "    r = random.choice(list(coragraph.nodes()))\n",
    "    if r not in test:\n",
    "        test.append(r)\n",
    "to_visit = [x for x in test]\n",
    "while len(test) < test_size and len(to_visit) > 0:\n",
    "    next_visit = to_visit.pop(0)\n",
    "    for edge in nx.edges(coragraph, nbunch=(next_visit)):\n",
    "        v = edge[1]\n",
    "        if v not in to_visit and v not in test and len(test) < test_size:\n",
    "            test.append(v)\n",
    "            to_visit.append(v)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def split(lst):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for i in range(len(lst)):\n",
    "        node = str(coraatts_arr[i][0])\n",
    "        if node in test:\n",
    "            test_set.append(lst[i])\n",
    "        else:\n",
    "            train_set.append(lst[i])\n",
    "    return np.asarray(train_set), np.asarray(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "# Use node features\n",
    "Y = coraatts_arr[::,1434]\n",
    "features = coraatts_arr[::, 1:1434]\n",
    "feat_train, feat_test = split(features)\n",
    "Y_train, Y_test = split(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9796860572483841\n",
      "Confusion matrix: \n",
      "[[  9   0   4   2   2   1   2]\n",
      " [ 10 216  54   3  18   8  12]\n",
      " [  5   2  87   4   8   1   8]\n",
      " [  1   0   4  15   2   1   2]\n",
      " [  4   3   6   0  18   3   3]\n",
      " [  0   0   2   0   0   1   1]\n",
      " [  3   0   4   1   2   3   7]]\n",
      "Accuracy: 0.6512915129151291\n"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier( max_depth=64)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 15   0   1   0   1   0   3]\n",
      " [ 12 246  26   7  12   7  11]\n",
      " [  6   2  93   6   3   2   3]\n",
      " [  1   0   3  20   0   0   1]\n",
      " [  1   4   5   0  22   4   1]\n",
      " [  0   0   0   0   0   2   2]\n",
      " [  1   0   3   1   0   5  10]]\n",
      "Accuracy: 0.7527675276752768\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# Use SVD of transition matrix\n",
    "feat_train, feat_test = split(svdA_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9362880886426593\n",
      "Confusion matrix: \n",
      "[[  6   3   5   2   2   0   2]\n",
      " [  9 106  35  72  94   1   4]\n",
      " [  4   1  63  21  19   2   5]\n",
      " [  1   1   2  20   1   0   0]\n",
      " [  2   5   3   6  20   0   1]\n",
      " [  4   0   0   0   0   0   0]\n",
      " [  2   3   7   2   3   1   2]]\n",
      "Accuracy: 0.4003690036900369\n"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier( max_depth=46)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 13   3   0   0   2   1   1]\n",
      " [  4 217  91   1   5   0   3]\n",
      " [  3  56  40   7   3   0   6]\n",
      " [  0   1   3  21   0   0   0]\n",
      " [  0  20   2   0  14   0   1]\n",
      " [  4   0   0   0   0   0   0]\n",
      " [  1   9   3   0   0   2   5]]\n",
      "Accuracy: 0.5719557195571956\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# use laplacian SVD\n",
    "feat_train, feat_test = split(svdL_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9889196675900277\n",
      "Confusion matrix: \n",
      "[[ 14   2   3   0   1   0   0]\n",
      " [  3 258  23   1  31   3   2]\n",
      " [  3   4  98   2   1   3   4]\n",
      " [  1   0   2  22   0   0   0]\n",
      " [  1   9   5   0  21   0   1]\n",
      " [  3   0   0   0   0   1   0]\n",
      " [  2   1   4   0   2   1  10]]\n",
      "Accuracy: 0.7822878228782287\n"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree classifier\n",
    "dtree = DecisionTreeClassifier( max_depth=46)\n",
    "\n",
    "dtree.fit(feat_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(dtree.score(feat_train, Y_train)))\n",
    "\n",
    "# Predict and evaluate model\n",
    "Y_pred = dtree.predict(feat_test)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: \n",
      " [[ 14   3   0   0   1   2   0]\n",
      " [  2 311   6   0   1   0   1]\n",
      " [  0   4  95   1   8   2   5]\n",
      " [  0   0   4  18   3   0   0]\n",
      " [  0  14   2   0  21   0   0]\n",
      " [  4   0   0   0   0   0   0]\n",
      " [  2   3   6   0   2   2   5]]\n",
      "Accuracy: 0.8560885608856088\n"
     ]
    }
   ],
   "source": [
    "# Learn a logistic regression model\n",
    "#learn:\n",
    "lr=LogisticRegression(solver=\"lbfgs\",class_weight=\"balanced\")\n",
    "lr.fit(feat_train,Y_train)\n",
    "\n",
    "#test:\n",
    "Y_pred=lr.predict(feat_test)\n",
    "\n",
    "#evaluate:\n",
    "print(\"Test data confusion matrix: \\n {}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task 4:** Implement the label propagation algorithm (either iterative or random walk version). Evaluate and compare the accuracy on the two different train/test split constructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def rw_mat(test):\n",
    "    result = []\n",
    "    for i in range(len(A)):\n",
    "        id = str(coraatts_arr[i][0])\n",
    "        if id in test:\n",
    "            count = np.sum(A[i])\n",
    "            result.append(A[i] / count)\n",
    "        else:\n",
    "            result.append(np.zeros(len(A)))\n",
    "    return np.asarray(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def label_propagation(lst):\n",
    "    result = []\n",
    "    rw = rw_mat(lst)\n",
    "    idxs = [str(x) for x in coraatts_arr[::,0]]\n",
    "    n = 0\n",
    "    for node in lst:\n",
    "        print(f'{n} of {len(lst)}')\n",
    "        n +=1\n",
    "        idx = idxs.index(node)\n",
    "        start = np.zeros(len(rw))\n",
    "        start[idx] = 1\n",
    "        flag = 1\n",
    "        border = 1 / 10 ** 8\n",
    "        reps = 0\n",
    "        while flag > border and reps < 100:\n",
    "            next = np.asarray(np.dot(start, rw)).flatten()\n",
    "            flag = np.sum(np.abs(next - start))\n",
    "            start = next\n",
    "            reps += 1\n",
    "        labels = {'dunno': 0.0}\n",
    "        for i in range(len(start)):\n",
    "            if start[i] > 0:\n",
    "                l = Y[i]\n",
    "                if i in labels.keys():\n",
    "                    labels[l] += start[i]\n",
    "                else:\n",
    "                    labels[l] = start[i]\n",
    "        ls = list(labels.keys())\n",
    "        ls.sort(key=lambda x: labels[x], reverse=True)\n",
    "        result.append(ls[0]) if len(ls) > 0 else 'dunno'\n",
    "    return np.asarray(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp/ipykernel_23812/1557283634.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 136\n",
      "1 of 136\n",
      "2 of 136\n",
      "3 of 136\n",
      "4 of 136\n",
      "5 of 136\n",
      "6 of 136\n",
      "7 of 136\n",
      "8 of 136\n",
      "9 of 136\n",
      "10 of 136\n",
      "11 of 136\n",
      "12 of 136\n",
      "13 of 136\n",
      "14 of 136\n",
      "15 of 136\n",
      "16 of 136\n",
      "17 of 136\n",
      "18 of 136\n",
      "19 of 136\n",
      "20 of 136\n",
      "21 of 136\n",
      "22 of 136\n",
      "23 of 136\n",
      "24 of 136\n",
      "25 of 136\n",
      "26 of 136\n",
      "27 of 136\n",
      "28 of 136\n",
      "29 of 136\n",
      "30 of 136\n",
      "31 of 136\n",
      "32 of 136\n",
      "33 of 136\n",
      "34 of 136\n",
      "35 of 136\n",
      "36 of 136\n",
      "37 of 136\n",
      "38 of 136\n",
      "39 of 136\n",
      "40 of 136\n",
      "41 of 136\n",
      "42 of 136\n",
      "43 of 136\n",
      "44 of 136\n",
      "45 of 136\n",
      "46 of 136\n",
      "47 of 136\n",
      "48 of 136\n",
      "49 of 136\n",
      "50 of 136\n",
      "51 of 136\n",
      "52 of 136\n",
      "53 of 136\n",
      "54 of 136\n",
      "55 of 136\n",
      "56 of 136\n",
      "57 of 136\n",
      "58 of 136\n",
      "59 of 136\n",
      "60 of 136\n",
      "61 of 136\n",
      "62 of 136\n",
      "63 of 136\n",
      "64 of 136\n",
      "65 of 136\n",
      "66 of 136\n",
      "67 of 136\n",
      "68 of 136\n",
      "69 of 136\n",
      "70 of 136\n",
      "71 of 136\n",
      "72 of 136\n",
      "73 of 136\n",
      "74 of 136\n",
      "75 of 136\n",
      "76 of 136\n",
      "77 of 136\n",
      "78 of 136\n",
      "79 of 136\n",
      "80 of 136\n",
      "81 of 136\n",
      "82 of 136\n",
      "83 of 136\n",
      "84 of 136\n",
      "85 of 136\n",
      "86 of 136\n",
      "87 of 136\n",
      "88 of 136\n",
      "89 of 136\n",
      "90 of 136\n",
      "91 of 136\n",
      "92 of 136\n",
      "93 of 136\n",
      "94 of 136\n",
      "95 of 136\n",
      "96 of 136\n",
      "97 of 136\n",
      "98 of 136\n",
      "99 of 136\n",
      "100 of 136\n",
      "101 of 136\n",
      "102 of 136\n",
      "103 of 136\n",
      "104 of 136\n",
      "105 of 136\n",
      "106 of 136\n",
      "107 of 136\n",
      "108 of 136\n",
      "109 of 136\n",
      "110 of 136\n",
      "111 of 136\n",
      "112 of 136\n",
      "113 of 136\n",
      "114 of 136\n",
      "115 of 136\n",
      "116 of 136\n",
      "117 of 136\n",
      "118 of 136\n",
      "119 of 136\n",
      "120 of 136\n",
      "121 of 136\n",
      "122 of 136\n",
      "123 of 136\n",
      "124 of 136\n",
      "125 of 136\n",
      "126 of 136\n",
      "127 of 136\n",
      "128 of 136\n",
      "129 of 136\n",
      "130 of 136\n",
      "131 of 136\n",
      "132 of 136\n",
      "133 of 136\n",
      "134 of 136\n",
      "135 of 136\n"
     ]
    }
   ],
   "source": [
    "feat_train, feat_test = split(list(coragraph.nodes()))\n",
    "Y_pred = label_propagation(feat_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[ 0  9  0  0  0  0  0]\n",
      " [ 0  2  1  0  0  0  0]\n",
      " [ 0  2 99  0  0  0  0]\n",
      " [ 0  0  2  5  0  0  0]\n",
      " [ 0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1]\n",
      " [ 0  0  2  0  0  1  4]]\n",
      "Accuracy: 0.8161764705882353\n"
     ]
    }
   ],
   "source": [
    "Y_train, Y_test = split(Y)\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp/ipykernel_23812/1557283634.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 542\n",
      "1 of 542\n",
      "2 of 542\n",
      "3 of 542\n",
      "4 of 542\n",
      "5 of 542\n",
      "6 of 542\n",
      "7 of 542\n",
      "8 of 542\n",
      "9 of 542\n",
      "10 of 542\n",
      "11 of 542\n",
      "12 of 542\n",
      "13 of 542\n",
      "14 of 542\n",
      "15 of 542\n",
      "16 of 542\n",
      "17 of 542\n",
      "18 of 542\n",
      "19 of 542\n",
      "20 of 542\n",
      "21 of 542\n",
      "22 of 542\n",
      "23 of 542\n",
      "24 of 542\n",
      "25 of 542\n",
      "26 of 542\n",
      "27 of 542\n",
      "28 of 542\n",
      "29 of 542\n",
      "30 of 542\n",
      "31 of 542\n",
      "32 of 542\n",
      "33 of 542\n",
      "34 of 542\n",
      "35 of 542\n",
      "36 of 542\n",
      "37 of 542\n",
      "38 of 542\n",
      "39 of 542\n",
      "40 of 542\n",
      "41 of 542\n",
      "42 of 542\n",
      "43 of 542\n",
      "44 of 542\n",
      "45 of 542\n",
      "46 of 542\n",
      "47 of 542\n",
      "48 of 542\n",
      "49 of 542\n",
      "50 of 542\n",
      "51 of 542\n",
      "52 of 542\n",
      "53 of 542\n",
      "54 of 542\n",
      "55 of 542\n",
      "56 of 542\n",
      "57 of 542\n",
      "58 of 542\n",
      "59 of 542\n",
      "60 of 542\n",
      "61 of 542\n",
      "62 of 542\n",
      "63 of 542\n",
      "64 of 542\n",
      "65 of 542\n",
      "66 of 542\n",
      "67 of 542\n",
      "68 of 542\n",
      "69 of 542\n",
      "70 of 542\n",
      "71 of 542\n",
      "72 of 542\n",
      "73 of 542\n",
      "74 of 542\n",
      "75 of 542\n",
      "76 of 542\n",
      "77 of 542\n",
      "78 of 542\n",
      "79 of 542\n",
      "80 of 542\n",
      "81 of 542\n",
      "82 of 542\n",
      "83 of 542\n",
      "84 of 542\n",
      "85 of 542\n",
      "86 of 542\n",
      "87 of 542\n",
      "88 of 542\n",
      "89 of 542\n",
      "90 of 542\n",
      "91 of 542\n",
      "92 of 542\n",
      "93 of 542\n",
      "94 of 542\n",
      "95 of 542\n",
      "96 of 542\n",
      "97 of 542\n",
      "98 of 542\n",
      "99 of 542\n",
      "100 of 542\n",
      "101 of 542\n",
      "102 of 542\n",
      "103 of 542\n",
      "104 of 542\n",
      "105 of 542\n",
      "106 of 542\n",
      "107 of 542\n",
      "108 of 542\n",
      "109 of 542\n",
      "110 of 542\n",
      "111 of 542\n",
      "112 of 542\n",
      "113 of 542\n",
      "114 of 542\n",
      "115 of 542\n",
      "116 of 542\n",
      "117 of 542\n",
      "118 of 542\n",
      "119 of 542\n",
      "120 of 542\n",
      "121 of 542\n",
      "122 of 542\n",
      "123 of 542\n",
      "124 of 542\n",
      "125 of 542\n",
      "126 of 542\n",
      "127 of 542\n",
      "128 of 542\n",
      "129 of 542\n",
      "130 of 542\n",
      "131 of 542\n",
      "132 of 542\n",
      "133 of 542\n",
      "134 of 542\n",
      "135 of 542\n",
      "136 of 542\n",
      "137 of 542\n",
      "138 of 542\n",
      "139 of 542\n",
      "140 of 542\n",
      "141 of 542\n",
      "142 of 542\n",
      "143 of 542\n",
      "144 of 542\n",
      "145 of 542\n",
      "146 of 542\n",
      "147 of 542\n",
      "148 of 542\n",
      "149 of 542\n",
      "150 of 542\n",
      "151 of 542\n",
      "152 of 542\n",
      "153 of 542\n",
      "154 of 542\n",
      "155 of 542\n",
      "156 of 542\n",
      "157 of 542\n",
      "158 of 542\n",
      "159 of 542\n",
      "160 of 542\n",
      "161 of 542\n",
      "162 of 542\n",
      "163 of 542\n",
      "164 of 542\n",
      "165 of 542\n",
      "166 of 542\n",
      "167 of 542\n",
      "168 of 542\n",
      "169 of 542\n",
      "170 of 542\n",
      "171 of 542\n",
      "172 of 542\n",
      "173 of 542\n",
      "174 of 542\n",
      "175 of 542\n",
      "176 of 542\n",
      "177 of 542\n",
      "178 of 542\n",
      "179 of 542\n",
      "180 of 542\n",
      "181 of 542\n",
      "182 of 542\n",
      "183 of 542\n",
      "184 of 542\n",
      "185 of 542\n",
      "186 of 542\n",
      "187 of 542\n",
      "188 of 542\n",
      "189 of 542\n",
      "190 of 542\n",
      "191 of 542\n",
      "192 of 542\n",
      "193 of 542\n",
      "194 of 542\n",
      "195 of 542\n",
      "196 of 542\n",
      "197 of 542\n",
      "198 of 542\n",
      "199 of 542\n",
      "200 of 542\n",
      "201 of 542\n",
      "202 of 542\n",
      "203 of 542\n",
      "204 of 542\n",
      "205 of 542\n",
      "206 of 542\n",
      "207 of 542\n",
      "208 of 542\n",
      "209 of 542\n",
      "210 of 542\n",
      "211 of 542\n",
      "212 of 542\n",
      "213 of 542\n",
      "214 of 542\n",
      "215 of 542\n",
      "216 of 542\n",
      "217 of 542\n",
      "218 of 542\n",
      "219 of 542\n",
      "220 of 542\n",
      "221 of 542\n",
      "222 of 542\n",
      "223 of 542\n",
      "224 of 542\n",
      "225 of 542\n",
      "226 of 542\n",
      "227 of 542\n",
      "228 of 542\n",
      "229 of 542\n",
      "230 of 542\n",
      "231 of 542\n",
      "232 of 542\n",
      "233 of 542\n",
      "234 of 542\n",
      "235 of 542\n",
      "236 of 542\n",
      "237 of 542\n",
      "238 of 542\n",
      "239 of 542\n",
      "240 of 542\n",
      "241 of 542\n",
      "242 of 542\n",
      "243 of 542\n",
      "244 of 542\n",
      "245 of 542\n",
      "246 of 542\n",
      "247 of 542\n",
      "248 of 542\n",
      "249 of 542\n",
      "250 of 542\n",
      "251 of 542\n",
      "252 of 542\n",
      "253 of 542\n",
      "254 of 542\n",
      "255 of 542\n",
      "256 of 542\n",
      "257 of 542\n",
      "258 of 542\n",
      "259 of 542\n",
      "260 of 542\n",
      "261 of 542\n",
      "262 of 542\n",
      "263 of 542\n",
      "264 of 542\n",
      "265 of 542\n",
      "266 of 542\n",
      "267 of 542\n",
      "268 of 542\n",
      "269 of 542\n",
      "270 of 542\n",
      "271 of 542\n",
      "272 of 542\n",
      "273 of 542\n",
      "274 of 542\n",
      "275 of 542\n",
      "276 of 542\n",
      "277 of 542\n",
      "278 of 542\n",
      "279 of 542\n",
      "280 of 542\n",
      "281 of 542\n",
      "282 of 542\n",
      "283 of 542\n",
      "284 of 542\n",
      "285 of 542\n",
      "286 of 542\n",
      "287 of 542\n",
      "288 of 542\n",
      "289 of 542\n",
      "290 of 542\n",
      "291 of 542\n",
      "292 of 542\n",
      "293 of 542\n",
      "294 of 542\n",
      "295 of 542\n",
      "296 of 542\n",
      "297 of 542\n",
      "298 of 542\n",
      "299 of 542\n",
      "300 of 542\n",
      "301 of 542\n",
      "302 of 542\n",
      "303 of 542\n",
      "304 of 542\n",
      "305 of 542\n",
      "306 of 542\n",
      "307 of 542\n",
      "308 of 542\n",
      "309 of 542\n",
      "310 of 542\n",
      "311 of 542\n",
      "312 of 542\n",
      "313 of 542\n",
      "314 of 542\n",
      "315 of 542\n",
      "316 of 542\n",
      "317 of 542\n",
      "318 of 542\n",
      "319 of 542\n",
      "320 of 542\n",
      "321 of 542\n",
      "322 of 542\n",
      "323 of 542\n",
      "324 of 542\n",
      "325 of 542\n",
      "326 of 542\n",
      "327 of 542\n",
      "328 of 542\n",
      "329 of 542\n",
      "330 of 542\n",
      "331 of 542\n",
      "332 of 542\n",
      "333 of 542\n",
      "334 of 542\n",
      "335 of 542\n",
      "336 of 542\n",
      "337 of 542\n",
      "338 of 542\n",
      "339 of 542\n",
      "340 of 542\n",
      "341 of 542\n",
      "342 of 542\n",
      "343 of 542\n",
      "344 of 542\n",
      "345 of 542\n",
      "346 of 542\n",
      "347 of 542\n",
      "348 of 542\n",
      "349 of 542\n",
      "350 of 542\n",
      "351 of 542\n",
      "352 of 542\n",
      "353 of 542\n",
      "354 of 542\n",
      "355 of 542\n",
      "356 of 542\n",
      "357 of 542\n",
      "358 of 542\n",
      "359 of 542\n",
      "360 of 542\n",
      "361 of 542\n",
      "362 of 542\n",
      "363 of 542\n",
      "364 of 542\n",
      "365 of 542\n",
      "366 of 542\n",
      "367 of 542\n",
      "368 of 542\n",
      "369 of 542\n",
      "370 of 542\n",
      "371 of 542\n",
      "372 of 542\n",
      "373 of 542\n",
      "374 of 542\n",
      "375 of 542\n",
      "376 of 542\n",
      "377 of 542\n",
      "378 of 542\n",
      "379 of 542\n",
      "380 of 542\n",
      "381 of 542\n",
      "382 of 542\n",
      "383 of 542\n",
      "384 of 542\n",
      "385 of 542\n",
      "386 of 542\n",
      "387 of 542\n",
      "388 of 542\n",
      "389 of 542\n",
      "390 of 542\n",
      "391 of 542\n",
      "392 of 542\n",
      "393 of 542\n",
      "394 of 542\n",
      "395 of 542\n",
      "396 of 542\n",
      "397 of 542\n",
      "398 of 542\n",
      "399 of 542\n",
      "400 of 542\n",
      "401 of 542\n",
      "402 of 542\n",
      "403 of 542\n",
      "404 of 542\n",
      "405 of 542\n",
      "406 of 542\n",
      "407 of 542\n",
      "408 of 542\n",
      "409 of 542\n",
      "410 of 542\n",
      "411 of 542\n",
      "412 of 542\n",
      "413 of 542\n",
      "414 of 542\n",
      "415 of 542\n",
      "416 of 542\n",
      "417 of 542\n",
      "418 of 542\n",
      "419 of 542\n",
      "420 of 542\n",
      "421 of 542\n",
      "422 of 542\n",
      "423 of 542\n",
      "424 of 542\n",
      "425 of 542\n",
      "426 of 542\n",
      "427 of 542\n",
      "428 of 542\n",
      "429 of 542\n",
      "430 of 542\n",
      "431 of 542\n",
      "432 of 542\n",
      "433 of 542\n",
      "434 of 542\n",
      "435 of 542\n",
      "436 of 542\n",
      "437 of 542\n",
      "438 of 542\n",
      "439 of 542\n",
      "440 of 542\n",
      "441 of 542\n",
      "442 of 542\n",
      "443 of 542\n",
      "444 of 542\n",
      "445 of 542\n",
      "446 of 542\n",
      "447 of 542\n",
      "448 of 542\n",
      "449 of 542\n",
      "450 of 542\n",
      "451 of 542\n",
      "452 of 542\n",
      "453 of 542\n",
      "454 of 542\n",
      "455 of 542\n",
      "456 of 542\n",
      "457 of 542\n",
      "458 of 542\n",
      "459 of 542\n",
      "460 of 542\n",
      "461 of 542\n",
      "462 of 542\n",
      "463 of 542\n",
      "464 of 542\n",
      "465 of 542\n",
      "466 of 542\n",
      "467 of 542\n",
      "468 of 542\n",
      "469 of 542\n",
      "470 of 542\n",
      "471 of 542\n",
      "472 of 542\n",
      "473 of 542\n",
      "474 of 542\n",
      "475 of 542\n",
      "476 of 542\n",
      "477 of 542\n",
      "478 of 542\n",
      "479 of 542\n",
      "480 of 542\n",
      "481 of 542\n",
      "482 of 542\n",
      "483 of 542\n",
      "484 of 542\n",
      "485 of 542\n",
      "486 of 542\n",
      "487 of 542\n",
      "488 of 542\n",
      "489 of 542\n",
      "490 of 542\n",
      "491 of 542\n",
      "492 of 542\n",
      "493 of 542\n",
      "494 of 542\n",
      "495 of 542\n",
      "496 of 542\n",
      "497 of 542\n",
      "498 of 542\n",
      "499 of 542\n",
      "500 of 542\n",
      "501 of 542\n",
      "502 of 542\n",
      "503 of 542\n",
      "504 of 542\n",
      "505 of 542\n",
      "506 of 542\n",
      "507 of 542\n",
      "508 of 542\n",
      "509 of 542\n",
      "510 of 542\n",
      "511 of 542\n",
      "512 of 542\n",
      "513 of 542\n",
      "514 of 542\n",
      "515 of 542\n",
      "516 of 542\n",
      "517 of 542\n",
      "518 of 542\n",
      "519 of 542\n",
      "520 of 542\n",
      "521 of 542\n",
      "522 of 542\n",
      "523 of 542\n",
      "524 of 542\n",
      "525 of 542\n",
      "526 of 542\n",
      "527 of 542\n",
      "528 of 542\n",
      "529 of 542\n",
      "530 of 542\n",
      "531 of 542\n",
      "532 of 542\n",
      "533 of 542\n",
      "534 of 542\n",
      "535 of 542\n",
      "536 of 542\n",
      "537 of 542\n",
      "538 of 542\n",
      "539 of 542\n",
      "540 of 542\n",
      "541 of 542\n",
      "Confusion matrix: \n",
      "[[30  0  1  0  1  1  4 30]\n",
      " [ 0 32  6  0  3  1  0 32]\n",
      " [ 1  2 60  2  3  3  1 92]\n",
      " [ 0  0  1 33  1  0  4 48]\n",
      " [ 3  3  3  0 20  1  2 18]\n",
      " [ 1  1  2  0  3 10  4 14]\n",
      " [ 7  5  5  2  1  1 12 32]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Accuracy: 0.3634686346863469\n"
     ]
    }
   ],
   "source": [
    "feat_train, feat_test, Y_train, Y_test = train_test_split(list(coragraph.nodes),Y, train_size=0.8)\n",
    "Y_pred = label_propagation(feat_test)\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(Y_test,Y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y_test,Y_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}