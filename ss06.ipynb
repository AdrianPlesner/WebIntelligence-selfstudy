{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self study 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this self study we directly continue with what we started in self study 5\n",
    "\n",
    "**Task 2:** For the same user, and the same train/test split, implement the user-based neighborhood method. How does the RMSE compare to what you got in the content-based approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#Load data\n",
    "R=np.genfromtxt('u.data',dtype=int)\n",
    "\n",
    "#Sort users per number of ratings\n",
    "Nratings=np.zeros(943)\n",
    "for i in range(943):\n",
    "    Nratings[i]=len(np.where(R[:,0]==i+1)[0])\n",
    "\n",
    "#Get users with most ratings and make train/test split\n",
    "users = np.where(Nratings>500)\n",
    "ratID = np.where(R[::,0] == users[0][3]+1)\n",
    "ratings = [R[i, 1:3] for i in ratID[0]]\n",
    "\n",
    "split = len(ratings) // 3\n",
    "train = pd.DataFrame(ratings[:2*split], columns=[\"Movie ID\", \"Rating\"])\n",
    "test = pd.DataFrame(ratings[2*split:], columns=[\"Movie ID\", \"Rating\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Make a prediction for a movie\n",
    "def estimate_rating(train, movie, user):\n",
    "    # Get all user which have rated the movie\n",
    "    users = np.where(R[::,1] == movie)\n",
    "    # Perform mean centering on original user vector\n",
    "    avg_rating = np.average(train[\"Rating\"])\n",
    "    train[\"Relative Rating\"] = train[\"Rating\"] - avg_rating\n",
    "    users_with_ratings = []\n",
    "    # Extract user IDs\n",
    "    users = [R[i,0] for i in users[0] if i != user]\n",
    "    for us in users:\n",
    "        # Extract the ratings of each user\n",
    "        ratIDs = np.where(R[::,0] == us)[0]\n",
    "        ratings = np.asarray([R[i,1:3] for i in ratIDs])\n",
    "        # Perfrom mean centering on user vector\n",
    "        user_avg = np.average(ratings[::,1])\n",
    "        ratings = np.c_[ratings, [row[1] - user_avg for row in ratings]]\n",
    "        # Find common ratings\n",
    "        common_movies = [int(i) for i in ratings[::,0] if i in train[\"Movie ID\"].values]\n",
    "        common_movies.sort()\n",
    "        # Construct user vectors of common movies\n",
    "        old_user_ratings = np.asarray([train.values[[np.where(train[\"Movie ID\"].values == mov)[0]], 2][0] for mov in common_movies])[::,0]\n",
    "        new_user_ratings = np.asarray([ratings[np.where(ratings[::,0] == mov)[0], 2] for mov in common_movies])[::,0]\n",
    "        # Calculate cosine similarity with significance\n",
    "        sim = np.dot(old_user_ratings, new_user_ratings)/ (np.linalg.norm(old_user_ratings) * np.linalg.norm(new_user_ratings))\n",
    "        sim *= min([len(common_movies), 50]) / 50\n",
    "\n",
    "        users_with_ratings.append((sim, ratings[np.where(ratings[::,0] == movie)[0][0],2]))\n",
    "    # Sort users by similarity and choose top 50\n",
    "    users_with_ratings.sort(reverse=True, key= lambda x: x[0])\n",
    "    users_with_ratings = users_with_ratings[:50]\n",
    "    result = [x[1] for x in users_with_ratings]\n",
    "    return np.average(result) + avg_rating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7280623261159056"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rats = []\n",
    "for m in test.values:\n",
    "    r = estimate_rating(train, m[0], users[0][3]+1)\n",
    "    rats.append(r)\n",
    "rats = np.asarray(rats)\n",
    "\n",
    "truth = np.asarray(test['Rating'])\n",
    "RMSE = math.sqrt(np.average((truth-rats) ** 2))\n",
    "RMSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Now take the whole rating matrix. Divide all the ratings in the matrix into a train and a test set. For the user you have used in Tasks 1 and 2, you should include the same ratings in the test set as before. Be sure that you do the train/test division uniformly at random over all ratings, so that you don't get all the ratings of one movie (or one user) included in the test set (that would lead to some cold start problems).  You can also start with a sub-matrix of the whole rating matrix by selecting only a subset of users, and a subset of movies.\n",
    "\n",
    "Implement the gradient-descent approach for minimizing the error function for the ratings in the training set (you have to pick a value for the number of latent dimensions). Compare the RMSE values you obtain for the test user of tasks 1 and 2 with what you have previously obtained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}